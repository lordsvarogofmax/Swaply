import os
import logging
import asyncio
from flask import Flask, request
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import (
    Application,
    CommandHandler,
    MessageHandler,
    CallbackQueryHandler,
    ContextTypes,
    filters,
)
import httpx
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from datetime import datetime
from selectolax.parser import HTMLParser

# === –ù–∞—Å—Ç—Ä–æ–π–∫–∏ ===
BOT_TOKEN = "8379969489:AAGQNjLanMwL5vyKfsSfLc5kK5UObZnCQ5E"
OPENROUTER_API_KEY = "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"
MODEL = "meta-llama/llama-3.1-70b-instruct"

# === –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ ===
logging.basicConfig(
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    level=logging.INFO
)

# === –ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –∏–∑ base_knowledge/*.txt ===
_knowledge_chunks = []
knowledge_dir = "base_knowledge"

if os.path.exists(knowledge_dir):
    for filename in ["kniga-1.txt", "kniga-2.txt", "kniga-3.txt"]:
        path = os.path.join(knowledge_dir, filename)
        if os.path.exists(path):
            with open(path, "r", encoding="utf-8") as f:
                text = f.read().strip()
                # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞–Ω–∫–∏ –ø–æ ~500 —Å–ª–æ–≤
                sentences = text.split(". ")
                current_chunk = ""
                for sent in sentences:
                    if len(current_chunk.split()) + len(sent.split()) > 500:
                        if len(current_chunk) > 50:
                            _knowledge_chunks.append(current_chunk.strip())
                        current_chunk = sent + ". "
                    else:
                        current_chunk += sent + ". "
                if current_chunk and len(current_chunk) > 50:
                    _knowledge_chunks.append(current_chunk.strip())
        else:
            print(f"‚ö†Ô∏è –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {path}")

    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {_knowledge_chunks.__len__()} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –∏–∑ base_knowledge/")
else:
    print("‚ùå –ü–∞–ø–∫–∞ base_knowledge –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")

# –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º TF-IDF –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ç–æ—Ä
if _knowledge_chunks:
    _vectorizer = TfidfVectorizer(stop_words=None)
    _vectorizer.fit(_knowledge_chunks)
    _knowledge_ready = True
else:
    _knowledge_ready = False

# === –ü—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ ===
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    welcome_text = (
        "üë∑‚Äç‚ôÇÔ∏è **–Ø ‚Äî –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç –≤ —Å—Ñ–µ—Ä–µ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–∞ –∏ —Ä–µ–º–æ–Ω—Ç–∞.**\n\n"
        "–°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—Å—å –Ω–∞:\n"
        "‚Ä¢ –†–µ–º–æ–Ω—Ç–µ –∫–≤–∞—Ä—Ç–∏—Ä –∏ –¥–æ–º–æ–≤\n"
        "‚Ä¢ –û—Ç–¥–µ–ª–∫–µ (—à—Ç—É–∫–∞—Ç—É—Ä–∫–∞, –ø–æ–∫—Ä–∞—Å–∫–∞, –ø–ª–∏—Ç–∫–∞)\n"
        "‚Ä¢ –≠–ª–µ–∫—Ç—Ä–æ–º–æ–Ω—Ç–∞–∂–µ –∏ —Å–∞–Ω—Ç–µ—Ö–Ω–∏–∫–µ\n"
        "‚Ä¢ –í—ã–±–æ—Ä–µ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤ –∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤\n"
        "‚Ä¢ –†–∞—Å—á—ë—Ç–µ —Å–º–µ—Ç –∏ —Å—Ä–æ–∫–æ–≤\n\n"
        "‚Ä¢ –û—Ç–≤–µ—á—É –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ –°–ù–∏–ü–∞–º –∏ –ì–û–°–¢–∞–º\n\n"
        "‚ö†Ô∏è **–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ**: —è –æ—Ç–≤–µ—á–∞—é **—Ç–æ–ª—å–∫–æ –ø–æ —Ç–µ–º–µ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–∞ –∏ —Ä–µ–º–æ–Ω—Ç–∞**. "
        "–Ø –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é –≤–µ—Ç–∫—É –¥–∏–∞–ª–æ–≥–∞ –¥–æ 10 —Å–æ–æ–±—â–µ–Ω–∏–π\n\n"
        "–ì–æ—Ç–æ–≤ –ø–æ–º–æ—á—å –≤–∞–º —Å —Ä–µ–∞–ª—å–Ω–æ–π –∑–∞–¥–∞—á–µ–π ‚Äî –ø—Ä–æ—Å—Ç–æ –æ–ø–∏—à–∏—Ç–µ –µ—ë."
    )
    keyboard = [[InlineKeyboardButton("üí¨ –ü–æ–ª—É—á–∏—Ç—å –Ω–æ–≤—É—é –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—é", callback_data="ask")]]
    reply_markup = InlineKeyboardMarkup(keyboard)
    await update.message.reply_text(welcome_text, parse_mode="Markdown", reply_markup=reply_markup)

# === –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞–∂–∞—Ç–∏—è –∫–Ω–æ–ø–∫–∏ ===
async def ask_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()
    await query.edit_message_text(
        "üìù –ù–∞–ø–∏—à–∏—Ç–µ –≤–∞—à –≤–æ–ø—Ä–æ—Å –ø–æ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤—É –∏–ª–∏ —Ä–µ–º–æ–Ω—Ç—É. –ù–∞–ø—Ä–∏–º–µ—Ä:\n\n"
        "‚Ä¢ –ö–∞–∫ –≤—ã—Ä–æ–≤–Ω—è—Ç—å —Å—Ç–µ–Ω—ã –≥–∏–ø—Å–æ–∫–∞—Ä—Ç–æ–Ω–æ–º?\n"
        "‚Ä¢ –ù—É–∂–Ω–∞ –ª–∏ –≥–∏–¥—Ä–æ–∏–∑–æ–ª—è—Ü–∏—è –≤ –≤–∞–Ω–Ω–æ–π –ø–æ–¥ –ø–ª–∏—Ç–∫—É?\n"
        "‚Ä¢ –ö–∞–∫–æ–π –∫—Ä–∞—Å–∫–æ–π –ø–æ–∫—Ä–∞—Å–∏—Ç—å –¥–µ—Ä–µ–≤—è–Ω–Ω—ã–π –ø–æ–ª?\n\n"
        "–Ø –¥–∞–º —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—ã–π, –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—ã—Ö –Ω–æ—Ä–º –∏ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–æ–≤."
    )
    context.user_data["in_consultation"] = True

# === –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ ===
def retrieve_relevant_chunks(query, top_k=3):
    if not _knowledge_ready:
        return []
    query_vec = _vectorizer.transform([query])
    knowledge_vecs = _vectorizer.transform(_knowledge_chunks)
    similarities = cosine_similarity(query_vec, knowledge_vecs).flatten()
    top_indices = similarities.argsort()[-top_k:][::-1]
    return [_knowledge_chunks[i] for i in top_indices if similarities[i] > 0.1]

# === –ò—â–µ—Ç –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –Ω–∞ docs.cntd.ru ===

async def search_cntd(query: str, max_chars=1500) -> str:
    try:
        async with httpx.AsyncClient(
            timeout=10.0,
            follow_redirects=True,
            headers={
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36",
                "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8",
                "Accept-Language": "ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7",
                "Accept-Encoding": "gzip, deflate, br",
                "Connection": "keep-alive",
                "Upgrade-Insecure-Requests": "1",
                "Sec-Fetch-Dest": "document",
                "Sec-Fetch-Mode": "navigate",
                "Sec-Fetch-Site": "none",
                "Sec-Fetch-User": "?1",
            }
        ) as client:
            search_url = f"https://docs.cntd.ru/search?text={query}"
            response = await client.get(search_url)
            response.raise_for_status()

            # –ü–∞—Ä—Å–∏–Ω–≥ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
            tree = HTMLParser(response.text)
            results = []
            for item in tree.css("div.search-results__item"):
                title_node = item.css_first("a")
                if not title_node:
                    continue
                title = title_node.text().strip()
                href = title_node.attributes.get("href")
                if not href or not href.startswith("/document/"):
                    continue
                status_node = item.css_first("span.document-info__status")
                status = status_node.text().strip().lower() if status_node else ""
                if "–æ—Ç–º–µ–Ω" in status or "–Ω–µ –¥–µ–π—Å—Ç–≤—É–µ—Ç" in status:
                    continue
                results.append({"title": title, "url": "https://docs.cntd.ru" + href})

            if not results:
                return ""

            doc_url = results[0]["url"]
            doc_resp = await client.get(doc_url)
            doc_tree = HTMLParser(doc_resp.text)
            content = ""
            for p in doc_tree.css("div.document-content p"):
                text = p.text().strip()
                if text and len(text) > 20:
                    content += text + "\n"
                    if len(content) > max_chars:
                        break

            return f"[–ò—Å—Ç–æ—á–Ω–∏–∫: {results[0]['title']}]\n{content[:max_chars]}..." if content else ""

    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –Ω–∞ cntd.ru: {e}")
        return ""

# === –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π ===
async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not context.user_data.get("in_consultation", False):
        await start(update, context)
        return

    user_text = update.message.text.strip()

    # –ü—Ä–æ–≤–µ—Ä–∫–∞: –∑–∞–ø—Ä–æ—Å –ø—Ä–æ –Ω–æ—Ä–º–∞—Ç–∏–≤—ã?
    is_normative = any(word in user_text.lower() for word in [
        "—Å–Ω–∏–ø", "–≥–æ—Å—Ç", "—Å–ø ", "—Å–≤–æ–¥ –ø—Ä–∞–≤–∏–ª", "–∞–∫—Ç—É–∞–ª—å–Ω", "–¥–µ–π—Å—Ç–≤—É–µ—Ç",
        "–Ω–æ–≤—ã–π", "–Ω–æ—Ä–º—ã", "—Ç—Ä–µ–±–æ–≤–∞–Ω", "—Å—Ç–∞–Ω–¥–∞—Ä—Ç", "2025", "2024", "–æ–±–Ω–æ–≤–ª"
    ])

    relevant_chunks = []
    online_context = ""

    if is_normative:
        online_context = await search_cntd(user_text)
        if not online_context:
            # Fallback –Ω–∞ –ª–æ–∫–∞–ª—å–Ω—É—é –±–∞–∑—É
            relevant_chunks = retrieve_relevant_chunks(user_text)
    else:
        relevant_chunks = retrieve_relevant_chunks(user_text)

    # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
    if online_context:
        knowledge_context = online_context
    elif relevant_chunks:
        knowledge_context = "\n\n".join(relevant_chunks)
    else:
        knowledge_context = "–ù–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π."

    # –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç —Å —É–∫–∞–∑–∞–Ω–∏–µ–º –≥–æ–¥–∞
    current_year = datetime.now().year
    system_prompt = (
        f"–°–µ–≥–æ–¥–Ω—è {current_year} –≥–æ–¥. –¢—ã ‚Äî –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π —Å—Ç—Ä–æ–∏—Ç–µ–ª—å —Å 10-–ª–µ—Ç–Ω–∏–º –æ–ø—ã—Ç–æ–º. "
        "–¢—ã –æ—Ç–≤–µ—á–∞–µ—à—å –¢–û–õ–¨–ö–û –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤—É –∏ —Ä–µ–º–æ–Ω—Ç—É. "
        "–ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –Ω–µ –ø–æ —Ç–µ–º–µ ‚Äî –≤–µ–∂–ª–∏–≤–æ –æ—Ç–∫–∞–∂–∏—Å—å. "
        "–û–¢–í–ï–ß–ê–ô –¢–û–õ–¨–ö–û –ù–ê –†–£–°–°–ö–û–ú –Ø–ó–´–ö–ï. "
        "–ù–ï –ü–ò–®–ò –†–ê–°–°–£–ñ–î–ï–ù–ò–Ø. –ù–ï –ò–°–ü–û–õ–¨–ó–£–ô –§–†–ê–ó–´ –í–†–û–î–ï ¬´–Ø –¥—É–º–∞—é¬ª. "
        "–ü–ò–®–ò –ö–ê–ö –≠–ö–°–ü–ï–†–¢: –ö–†–ê–¢–ö–û, –¢–û–ß–ù–û, –ü–û –î–ï–õ–£. "
        "–ú–ê–ö–°–ò–ú–£–ú ‚Äî 400 —Å–ª–æ–≤."
    )

    if online_context or relevant_chunks:
        full_prompt = (
            f"{system_prompt}\n\n"
            f"–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—ã—Ö –Ω–æ—Ä–º–∞—Ç–∏–≤–æ–≤:\n{knowledge_context}\n\n"
            f"–í–æ–ø—Ä–æ—Å –∫–ª–∏–µ–Ω—Ç–∞: {user_text}\n\n"
            f"–û—Ç–≤–µ—Ç—å –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, –±–µ–∑ –ª–∏—à–Ω–∏—Ö —Å–ª–æ–≤."
        )
    else:
        full_prompt = f"{system_prompt}\n\n–í–æ–ø—Ä–æ—Å –∫–ª–∏–µ–Ω—Ç–∞: {user_text}\n\n–û—Ç–≤–µ—Ç—å –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, –±–µ–∑ –ª–∏—à–Ω–∏—Ö —Å–ª–æ–≤."

    await update.message.reply_text("‚è≥ –ú–∏–Ω—É—Ç–∫—É, –º–Ω–µ –Ω—É–∂–Ω–æ –ø–æ–¥—É–º–∞—Ç—å...")
    logging.info(f"–û—Ç–ø—Ä–∞–≤–ª—è—é –∑–∞–ø—Ä–æ—Å –∫ OpenRouter: {full_prompt[:200]}...")

    try:
        async with httpx.AsyncClient(timeout=30.0) as client:
            response = await client.post(
                "https://openrouter.ai/api/v1/chat/completions",  # ‚Üê –£–ë–†–ê–ù–´ –õ–ò–®–ù–ò–ï –ü–†–û–ë–ï–õ–´!
                headers={
                    "Authorization": f"Bearer {OPENROUTER_API_KEY}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": MODEL,
                    "messages": [{"role": "user", "content": full_prompt}],
                    "max_tokens": 1000,
                    "temperature": 0.3
                }
            )
            if response.status_code != 200:
                raise Exception(f"HTTP {response.status_code}: {response.text}")

            data = response.json()
            answer = data["choices"][0]["message"]["content"].strip()

            logging.info(f"–ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –æ—Ç OpenRouter: {answer[:200]}")

            keyboard = [[InlineKeyboardButton("üîÑ –ó–∞–¥–∞—Ç—å –Ω–æ–≤—ã–π –≤–æ–ø—Ä–æ—Å", callback_data="ask")]]
            reply_markup = InlineKeyboardMarkup(keyboard)

            await update.message.reply_text(
                answer,
                reply_markup=reply_markup,
                disable_web_page_preview=True
            )

    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ò–ò: {e}")
        await update.message.reply_text(
            "‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç. –í–æ–∑–º–æ–∂–Ω–æ, –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã —Å —Å–µ—Ä–≤–∏—Å–æ–º. "
            "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ —á–µ—Ä–µ–∑ –º–∏–Ω—É—Ç—É –∏–ª–∏ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π—Ç–µ –≤–æ–ø—Ä–æ—Å."
        )

# === Flask + Webhook ===
app = Flask(__name__)

application = Application.builder().token(BOT_TOKEN).build()

application.add_handler(CommandHandler("start", start))
application.add_handler(CallbackQueryHandler(ask_callback, pattern="^ask$"))
application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))

_loop = asyncio.new_event_loop()
asyncio.set_event_loop(_loop)
_loop.run_until_complete(application.initialize())

@app.route("/<path:token>", methods=["POST"])
def telegram_webhook(token):
    if token != BOT_TOKEN:
        return "Forbidden", 403
    data = request.get_json(force=True)
    update = Update.de_json(data, application.bot)
    _loop.run_until_complete(application.process_update(update))
    return "OK"

@app.route("/health")
def health():
    return "OK"

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 10000))
    app.run(host="0.0.0.0", port=port)
